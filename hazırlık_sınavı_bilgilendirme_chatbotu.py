# -*- coding: utf-8 -*-
"""hazÄ±rlÄ±k sÄ±navÄ± bilgilendirme chatbotu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CsHPdYl_EPWHkA4r4AVHe21wZbDI1Isa
"""

!pip install -q sentence-transformers chromadb gradio

# EÄŸer extracted_texts varsa birleÅŸtir; yoksa elle kÄ±sa belgeler kullan.
try:
    documents = extracted_texts  # hÃ¼cre 2 Ã§alÄ±ÅŸtÄ±ysa burada veri olur
    if not documents:
        raise Exception("no extracted texts")
except:
    documents = [
        {"id":"info1", "text":"SÄ±nav tarihi: 23.10.2025 PerÅŸembe. BaÅŸlangÄ±Ã§ saati 10:00, bitiÅŸ 12:40. Toplam sÃ¼re 2 saat 40 dakika."},
        {"id":"info2", "text":"SÄ±nav bÃ¶lÃ¼mleri: Writing, Listening, Reading."},
        {"id":"info3", "text":"Sorumlu konular: Ä°lk 3 Ã¼nite. Language Hub kitap etkinliklerine benzer sorular Ã§Ä±kabilir."},
        {"id":"faq1", "text":"Soru: SÄ±nav ne zaman? Cevap: 23.10.2025, 10:00'da baÅŸlÄ±yor."},
        {"id":"faq2", "text":"Soru: SÄ±nav sÃ¼resi ne kadar? Cevap: 2 saat 40 dakika (10:00 - 12:40)."}
    ]

print("Toplam dokÃ¼man sayÄ±sÄ±:", len(documents))
for d in documents[:5]:
    print("-", d["id"], "->", d["text"][:100].replace("\n"," "))

from sentence_transformers import SentenceTransformer
model_name = "all-MiniLM-L6-v2"  # hafif, hÄ±zlÄ±
embed_model = SentenceTransformer(model_name)
print("Embedding modeli yÃ¼klendi:", model_name)

def embed_texts(texts):
    # texts: list of strings
    return embed_model.encode(texts, show_progress_bar=False, convert_to_numpy=True)

import chromadb
from chromadb.config import Settings

# Local/ in-memory Chroma client
client = chromadb.Client(Settings(anonymized_telemetry=False))

# EÄŸer aynÄ± isimde koleksiyon varsa Ã¶nce silip yeniden oluÅŸtur (temizlik)
col_name = "exam_info_collection"
try:
    if col_name in [c.name for c in client.list_collections()]:
        client.delete_collection(col_name)
except Exception:
    pass

collection = client.create_collection(name=col_name)

# Prepare lists
ids = [d["id"] for d in documents]
texts = [d["text"] for d in documents]
metadatas = [{"source": d.get("id","local")} for d in documents]

# compute embeddings once (use embed_texts)
embs = embed_texts(texts)

# add to collection with embeddings
collection.add(ids=ids, documents=texts, metadatas=metadatas, embeddings=embs.tolist())
print("âœ… Chroma'ya eklendi:", collection.count(), "dokÃ¼man")

def retrieve(query, k=3):
    # chroma query; n_results = k
    res = collection.query(query_texts=[query], n_results=k, include=["documents","metadatas","distances"])
    docs = res["documents"][0]
    metas = res["metadatas"][0]
    distances = res["distances"][0]
    hits = []
    for d, m, dist in zip(docs, metas, distances):
        hits.append({"text": d, "metadata": m, "distance": dist})
    return hits

# Test
q = "SÄ±nav ne zaman baÅŸlÄ±yor?"
hits = retrieve(q, k=3)
for i,h in enumerate(hits,1):
    print(f"#{i} (dist={h['distance']:.4f}) -> {h['text'][:120].replace(chr(10),' ')}")

def generate_answer_rule_based(question, k=3):
    hits = retrieve(question, k=k)
    if not hits:
        return "Bu konuda veri yok."
    # En yakÄ±n dokÃ¼manÄ± al ve kÄ±saltarak cevap dÃ¶n
    top = hits[0]
    answer = f"Bulunan bilgi (kaynak: {top['metadata'].get('source','bilgi')}):\n{top['text']}"
    return answer

# Test
print(generate_answer_rule_based("SÄ±nav sÃ¼resi kaÃ§ dakika?"))

import gradio as gr

def chat_fn(user_input):
    return generate_answer_rule_based(user_input, k=2)

iface = gr.Interface(fn=chat_fn,
                     inputs=gr.Textbox(lines=2, placeholder="SÄ±nav hakkÄ±nda bir soru yaz..."),
                     outputs="text",
                     title="HazÄ±rlÄ±k SÄ±navÄ± - Mini Chatbot")
# Colab iÃ§in share=True kullan; Ã§alÄ±ÅŸtÄ±rÄ±nca bir URL verecek
iface.launch(share=True)

# birkaÃ§ Ã¶rnek soru dene
for q in ["SÄ±nav ne zaman?", "SÄ±nav sÃ¼resi nedir?", "Hangi bÃ¶lÃ¼mler var?"]:
    print("Soru:", q)
    print(generate_answer_rule_based(q))
    print("-"*40)

# FL3 seviyesiyle ilgili bilgi dokÃ¼manÄ± ekleme
new_docs2 = [
    {"id": "info_fl3", "text": "Bu sÄ±nav FL3 kurunda olan Ã¶ÄŸrenciler iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. Yani sÄ±nav iÃ§eriÄŸi ve zorluk seviyesi FL3 seviyesine uygundur."},
    {"id": "faq_fl3", "text": "Soru: Bu sÄ±nav hangi kur iÃ§in? Cevap: FL3 kurundaki Ã¶ÄŸrenciler iÃ§indir."}
]

# Embedding oluÅŸtur
new_texts2 = [d["text"] for d in new_docs2]
new_ids2 = [d["id"] for d in new_docs2]
new_metas2 = [{"source": d["id"]} for d in new_docs2]
new_embs2 = embed_texts(new_texts2)

# Koleksiyona ekle
collection.add(ids=new_ids2, documents=new_texts2, metadatas=new_metas2, embeddings=new_embs2.tolist())

print("âœ… FL3 bilgisi eklendi! Åu anda toplam belge sayÄ±sÄ±:", collection.count())

iface = gr.Interface(
    fn=chat_fn,
    inputs=gr.Textbox(lines=2, placeholder="SÄ±nav hakkÄ±nda soru yaz..."),
    outputs="text",
    title="HazÄ±rlÄ±k SÄ±navÄ± Chatbot (FL3 Kuru)",
    description="ğŸ’¬ Bu chatbot FL3 kurundaki Ã¶ÄŸrenciler iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. SÄ±nav tarihi, saat, iÃ§erik ve konular hakkÄ±nda bilgi verebilir."
)
iface.launch(share=True)

# SÄ±nav soru tipleriyle ilgili yeni dokÃ¼manlar
new_docs3 = [
    {
        "id": "info_question_types",
        "text": "SÄ±nav soru tipleri: Ã§oktan seÃ§meli, boÅŸluk doldurma ve eÅŸleÅŸtirme sorularÄ±ndan oluÅŸur. "
                "BazÄ± bÃ¶lÃ¼mlerde kÄ±sa yazma veya kelime tamamlama da bulunabilir."
    },
    {
        "id": "faq_question_types",
        "text": "Soru: SÄ±navda hangi tÃ¼r sorular var? "
                "Cevap: SÄ±nav Ã§oktan seÃ§meli, boÅŸluk doldurma ve eÅŸleÅŸtirme sorularÄ±ndan oluÅŸmaktadÄ±r."
    }
]

# Embedding oluÅŸtur
new_texts3 = [d["text"] for d in new_docs3]
new_ids3 = [d["id"] for d in new_docs3]
new_metas3 = [{"source": d["id"]} for d in new_docs3]
new_embs3 = embed_texts(new_texts3)

# Koleksiyona ekle
collection.add(ids=new_ids3, documents=new_texts3, metadatas=new_metas3, embeddings=new_embs3.tolist())

print("âœ… Soru tipi bilgisi eklendi! Åu anda toplam belge sayÄ±sÄ±:", collection.count())

# SÄ±nav yeri bilgisi ekleme
new_docs4 = [
    {
        "id": "info_location",
        "text": "SÄ±nav yeri: Hacettepe Ãœniversitesi Beytepe KampÃ¼sÃ¼ YabancÄ± Diller YÃ¼ksekokulu (YDYO) binasÄ±nda gerÃ§ekleÅŸecektir."
    },
    {
        "id": "faq_location",
        "text": "Soru: SÄ±nav nerede yapÄ±lacak? "
                "Cevap: Hacettepe Ãœniversitesi Beytepe KampÃ¼sÃ¼ YDYO binasÄ±nda yapÄ±lacaktÄ±r."
    }
]

# Embedding oluÅŸtur
new_texts4 = [d["text"] for d in new_docs4]
new_ids4 = [d["id"] for d in new_docs4]
new_metas4 = [{"source": d["id"]} for d in new_docs4]
new_embs4 = embed_texts(new_texts4)

# Koleksiyona ekle
collection.add(ids=new_ids4, documents=new_texts4, metadatas=new_metas4, embeddings=new_embs4.tolist())

print("âœ… SÄ±nav yeri bilgisi eklendi! Åu anda toplam belge sayÄ±sÄ±:", collection.count())

# SÄ±nava hazÄ±rlanma Ã¶nerileri (kaynak kitaplar) bilgisi
new_docs5 = [
    {
        "id": "info_study_materials",
        "text": "SÄ±nava hazÄ±rlanmak isteyen Ã¶ÄŸrenciler Language Hub kitabÄ±ndaki Ã¼niteleri tekrar etmeli "
                "ve Writer 2 kitabÄ±ndaki Ã¶rnek sorulara gÃ¶z atmalÄ±dÄ±r. "
                "Bu kaynaklardaki etkinlikler sÄ±nav formatÄ±na benzerdir."
    },
    {
        "id": "faq_study_materials",
        "text": "Soru: SÄ±nava nasÄ±l hazÄ±rlanabilirim? "
                "Cevap: Language Hub kitabÄ±na ve Writer 2 kitabÄ±ndaki Ã¶rnek sorulara Ã§alÄ±ÅŸabilirsiniz. "
                "Bu kitaplarda yer alan etkinlikler sÄ±nav sorularÄ±na benzer yapÄ±dadÄ±r."
    }
]

# Embedding oluÅŸtur
new_texts5 = [d["text"] for d in new_docs5]
new_ids5 = [d["id"] for d in new_docs5]
new_metas5 = [{"source": d["id"]} for d in new_docs5]
new_embs5 = embed_texts(new_texts5)

# Koleksiyona ekle
collection.add(ids=new_ids5, documents=new_texts5, metadatas=new_metas5, embeddings=new_embs5.tolist())

print("âœ… SÄ±nava hazÄ±rlÄ±k bilgisi eklendi! Åu anda toplam belge sayÄ±sÄ±:", collection.count())

iface.launch(share=True)